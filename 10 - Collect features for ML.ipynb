{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare features for all topics, disregarding the 'target' features. Later from the DFs with features we'll take only those topics that build our training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take features from Quita Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quita_features_file = './new_cleaned/all_quita_features_all_texts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>ATL_token</th>\n",
       "      <th>Entropy_lemma</th>\n",
       "      <th>VarEntropy_lemma</th>\n",
       "      <th>hpoint_lemma</th>\n",
       "      <th>mattr_lemma_100</th>\n",
       "      <th>mattr_lemma_25</th>\n",
       "      <th>mattr_lemma_50</th>\n",
       "      <th>TC_lemma</th>\n",
       "      <th>activity</th>\n",
       "      <th>descriptivity</th>\n",
       "      <th>verbdistance_lemma</th>\n",
       "      <th>zttr_FIClemma</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/10006</td>\n",
       "      <td>3.887262</td>\n",
       "      <td>6.815966</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.603356</td>\n",
       "      <td>0.850804</td>\n",
       "      <td>0.729842</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>-0.548987</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/10014</td>\n",
       "      <td>4.051695</td>\n",
       "      <td>7.080815</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0.589944</td>\n",
       "      <td>0.851419</td>\n",
       "      <td>0.728612</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>7.328571</td>\n",
       "      <td>-0.619795</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/10022</td>\n",
       "      <td>4.363095</td>\n",
       "      <td>7.413000</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.656161</td>\n",
       "      <td>0.866220</td>\n",
       "      <td>0.762795</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.462366</td>\n",
       "      <td>8.878788</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/10027</td>\n",
       "      <td>4.055164</td>\n",
       "      <td>6.981621</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.629920</td>\n",
       "      <td>0.863382</td>\n",
       "      <td>0.754446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>6.678899</td>\n",
       "      <td>-0.504511</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/10035</td>\n",
       "      <td>3.815013</td>\n",
       "      <td>6.930712</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.845114</td>\n",
       "      <td>0.741551</td>\n",
       "      <td>0.043239</td>\n",
       "      <td>0.647368</td>\n",
       "      <td>0.352632</td>\n",
       "      <td>8.065574</td>\n",
       "      <td>-0.627875</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text  ATL_token  Entropy_lemma  VarEntropy_lemma  hpoint_lemma  \\\n",
       "0  /10006   3.887262       6.815966          0.005011     12.000000   \n",
       "1  /10014   4.051695       7.080815          0.003463     15.200000   \n",
       "2  /10022   4.363095       7.413000          0.004039     13.500000   \n",
       "3  /10027   4.055164       6.981621          0.003852     12.666667   \n",
       "4  /10035   3.815013       6.930712          0.003942     15.500000   \n",
       "\n",
       "   mattr_lemma_100  mattr_lemma_25  mattr_lemma_50  TC_lemma  activity  \\\n",
       "0         0.603356        0.850804        0.729842  0.034531  0.728000   \n",
       "1         0.589944        0.851419        0.728612  0.027688  0.661972   \n",
       "2         0.656161        0.866220        0.762795  0.033896  0.537634   \n",
       "3         0.629920        0.863382        0.754446  0.000000  0.709677   \n",
       "4         0.611667        0.845114        0.741551  0.043239  0.647368   \n",
       "\n",
       "   descriptivity  verbdistance_lemma  zttr_FIClemma  topic_id  \n",
       "0       0.272000            6.500000      -0.548987       905  \n",
       "1       0.338028            7.328571      -0.619795       906  \n",
       "2       0.462366            8.878788       0.010507       909  \n",
       "3       0.290323            6.678899      -0.504511       910  \n",
       "4       0.352632            8.065574      -0.627875       911  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quita_features = pd.read_csv(quita_features_file)\n",
    "quita_features.head()\n",
    "\n",
    "# from this we don't need 'VarEntropy_lemma', 'descriptivity' \n",
    "# 'Text' is step id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See correlations between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571951192133077 0.0\n",
      "0.8484480688531248 0.0\n",
      "0.9408634476661891 0.0\n"
     ]
    }
   ],
   "source": [
    "# see if the 3 mattr attributes correlate\n",
    "coef1, pval1 = stats.spearmanr(quita_features['mattr_lemma_100'], quita_features['mattr_lemma_50'])\n",
    "coef2, pval2 = stats.spearmanr(quita_features['mattr_lemma_100'], quita_features['mattr_lemma_25'])\n",
    "coef3, pval3 = stats.spearmanr(quita_features['mattr_lemma_50'], quita_features['mattr_lemma_25'])\n",
    "\n",
    "print(coef1, pval1)\n",
    "print(coef2, pval2)\n",
    "print(coef3, pval3)\n",
    "\n",
    "# they do, so we'll take only one of them (50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy_lemma mattr_lemma_50\n",
      "0.6 0.0\n",
      "\n",
      "Entropy_lemma zttr_FIClemma\n",
      "0.78 0.0\n",
      "\n",
      "verbdistance_lemma activity\n",
      "-0.67 0.0\n",
      "\n",
      "mattr_lemma_50 zttr_FIClemma\n",
      "0.73 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_taking = ['hpoint_lemma', 'Entropy_lemma', 'verbdistance_lemma', 'activity', 'ATL_token', 'TC_lemma', \n",
    "               'mattr_lemma_50', 'zttr_FIClemma']\n",
    "\n",
    "for i, attribute1 in enumerate(list_taking):\n",
    "    for attribute2 in list_taking[i+1:]:\n",
    "        coef, pval = stats.spearmanr(quita_features[attribute1], quita_features[attribute2])\n",
    "        \n",
    "        if abs(coef) > 0.5 and pval < 0.05: \n",
    "            print(attribute1, attribute2)\n",
    "            print(round(coef, 2), round(pval, 2))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zttr_FIClemma correlates a lot with Entropy_lemma and mattr, so we'll not take it among the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DF with quita features for topic IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_needed_features = ['topic_id', 'hpoint_lemma', 'Entropy_lemma', 'verbdistance_lemma', 'activity', \n",
    "                        'ATL_token', 'TC_lemma', 'mattr_lemma_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>hpoint_lemma</th>\n",
       "      <th>Entropy_lemma</th>\n",
       "      <th>verbdistance_lemma</th>\n",
       "      <th>activity</th>\n",
       "      <th>ATL_token</th>\n",
       "      <th>TC_lemma</th>\n",
       "      <th>mattr_lemma_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>905</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.815966</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>3.887262</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.729842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>906</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>7.080815</td>\n",
       "      <td>7.328571</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>4.051695</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.728612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>7.413000</td>\n",
       "      <td>8.878788</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>4.363095</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.762795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>6.981621</td>\n",
       "      <td>6.678899</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>4.055164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>6.930712</td>\n",
       "      <td>8.065574</td>\n",
       "      <td>0.647368</td>\n",
       "      <td>3.815013</td>\n",
       "      <td>0.043239</td>\n",
       "      <td>0.741551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  hpoint_lemma  Entropy_lemma  verbdistance_lemma  activity  \\\n",
       "0       905     12.000000       6.815966            6.500000  0.728000   \n",
       "1       906     15.200000       7.080815            7.328571  0.661972   \n",
       "2       909     13.500000       7.413000            8.878788  0.537634   \n",
       "3       910     12.666667       6.981621            6.678899  0.709677   \n",
       "4       911     15.500000       6.930712            8.065574  0.647368   \n",
       "\n",
       "   ATL_token  TC_lemma  mattr_lemma_50  \n",
       "0   3.887262  0.034531        0.729842  \n",
       "1   4.051695  0.027688        0.728612  \n",
       "2   4.363095  0.033896        0.762795  \n",
       "3   4.055164  0.000000        0.754446  \n",
       "4   3.815013  0.043239        0.741551  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quita_needed_df = quita_features[only_needed_features]\n",
    "quita_needed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "quita_needed_df.to_csv('./new_cleaned/train_corpus/quita_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect other linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC score\n",
    "# Flesch score\n",
    "# average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id_step_id_mapping = pickle.load(open('topic_id_step_id_mapping.pkl', 'br'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_id_topic_id_mapping = pickle.load(open('step_id_topic_id_mapping.pkl', 'br'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_statistics = pd.read_csv('./new_cleaned/topics_all_statistics_and_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_id</th>\n",
       "      <th>is_theory</th>\n",
       "      <th>text</th>\n",
       "      <th>seconds_to_complete</th>\n",
       "      <th>last_3_month_completion_rate</th>\n",
       "      <th>last_3_month_completed_step_users_count</th>\n",
       "      <th>last_3_month_avg_like</th>\n",
       "      <th>last_3_month_likes_count</th>\n",
       "      <th>last_3_month_topic_completion_rate</th>\n",
       "      <th>last_3_month_completed_topic_users_count</th>\n",
       "      <th>...</th>\n",
       "      <th>cleaned_texts</th>\n",
       "      <th>num_headings</th>\n",
       "      <th>symbols_in_snippets</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>norm_seconds</th>\n",
       "      <th>ASL</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>dale_chall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12357</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;h5 id=\\\"introduction\\\"&gt; Introduction&lt;/h5&gt;\\n\\...</td>\n",
       "      <td>603.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\" *heading* So far you have learned quite a lo...</td>\n",
       "      <td>6</td>\n",
       "      <td>790</td>\n",
       "      <td>618</td>\n",
       "      <td>24</td>\n",
       "      <td>995</td>\n",
       "      <td>9.764563</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>44.490012</td>\n",
       "      <td>9.180577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12691</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;p&gt;JavaScript was originally developed as a l...</td>\n",
       "      <td>253.21</td>\n",
       "      <td>0.87</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\"JavaScript was originally developed as a lang...</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>605</td>\n",
       "      <td>35</td>\n",
       "      <td>962</td>\n",
       "      <td>4.185289</td>\n",
       "      <td>17.285714</td>\n",
       "      <td>54.769008</td>\n",
       "      <td>9.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8112</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;p&gt;We've already learned what annotations are...</td>\n",
       "      <td>486.94</td>\n",
       "      <td>0.45</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\"We've already learned what annotations are an...</td>\n",
       "      <td>3</td>\n",
       "      <td>1506</td>\n",
       "      <td>610</td>\n",
       "      <td>30</td>\n",
       "      <td>990</td>\n",
       "      <td>7.982623</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>48.895027</td>\n",
       "      <td>9.097296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7892</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;h5&gt;Introduction&lt;/h5&gt;\\n\\n&lt;p&gt;You often hear pe...</td>\n",
       "      <td>542.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\" *heading* You often hear people speak about ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1079</td>\n",
       "      <td>51</td>\n",
       "      <td>1652</td>\n",
       "      <td>5.029935</td>\n",
       "      <td>21.156863</td>\n",
       "      <td>55.834186</td>\n",
       "      <td>9.207762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15809</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;h5&gt;Introduction&lt;/h5&gt;\\n\\n&lt;p&gt;When you have alr...</td>\n",
       "      <td>556.76</td>\n",
       "      <td>0.43</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\" *heading* When you have already learned the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>409</td>\n",
       "      <td>633</td>\n",
       "      <td>21</td>\n",
       "      <td>995</td>\n",
       "      <td>8.795577</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>43.258957</td>\n",
       "      <td>9.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_id  is_theory                                               text  \\\n",
       "0    12357          1  \"<h5 id=\\\"introduction\\\"> Introduction</h5>\\n\\...   \n",
       "1    12691          1  \"<p>JavaScript was originally developed as a l...   \n",
       "2     8112          1  \"<p>We've already learned what annotations are...   \n",
       "3     7892          1  \"<h5>Introduction</h5>\\n\\n<p>You often hear pe...   \n",
       "4    15809          1  \"<h5>Introduction</h5>\\n\\n<p>When you have alr...   \n",
       "\n",
       "   seconds_to_complete  last_3_month_completion_rate  \\\n",
       "0               603.45                          0.56   \n",
       "1               253.21                          0.87   \n",
       "2               486.94                          0.45   \n",
       "3               542.73                          0.72   \n",
       "4               556.76                          0.43   \n",
       "\n",
       "   last_3_month_completed_step_users_count  last_3_month_avg_like  \\\n",
       "0                                     40.0                   2.00   \n",
       "1                                    884.0                   1.72   \n",
       "2                                     50.0                   1.57   \n",
       "3                                     60.0                   2.00   \n",
       "4                                     43.0                   1.40   \n",
       "\n",
       "   last_3_month_likes_count  last_3_month_topic_completion_rate  \\\n",
       "0                      10.0                                0.90   \n",
       "1                      79.0                                0.96   \n",
       "2                       7.0                                0.89   \n",
       "3                       5.0                                0.91   \n",
       "4                      10.0                                0.91   \n",
       "\n",
       "   last_3_month_completed_topic_users_count  ...  \\\n",
       "0                                      35.0  ...   \n",
       "1                                     844.0  ...   \n",
       "2                                      49.0  ...   \n",
       "3                                      58.0  ...   \n",
       "4                                      53.0  ...   \n",
       "\n",
       "                                       cleaned_texts  num_headings  \\\n",
       "0  \" *heading* So far you have learned quite a lo...             6   \n",
       "1  \"JavaScript was originally developed as a lang...             5   \n",
       "2  \"We've already learned what annotations are an...             3   \n",
       "3  \" *heading* You often hear people speak about ...             5   \n",
       "4  \" *heading* When you have already learned the ...             5   \n",
       "\n",
       "  symbols_in_snippets  num_words  num_sentences  num_syllables  norm_seconds  \\\n",
       "0                 790        618             24            995      9.764563   \n",
       "1                  35        605             35            962      4.185289   \n",
       "2                1506        610             30            990      7.982623   \n",
       "3                   0       1079             51           1652      5.029935   \n",
       "4                 409        633             21            995      8.795577   \n",
       "\n",
       "         ASL  flesch_score  dale_chall_score  \n",
       "0  25.750000     44.490012          9.180577  \n",
       "1  17.285714     54.769008          9.896400  \n",
       "2  20.333333     48.895027          9.097296  \n",
       "3  21.156863     55.834186          9.207762  \n",
       "4  30.142857     43.258957          9.721412  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features_df = quita_needed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319\n",
      "1318\n"
     ]
    }
   ],
   "source": [
    "# in ling features there's now one row more than in topic statistics; we need to delete this row\n",
    "\n",
    "print(ling_features_df.shape[0])\n",
    "\n",
    "bad_step_id = 16324\n",
    "bad_topic_id = step_id_topic_id_mapping[bad_step_id]\n",
    "ling_features_df = ling_features_df.drop(ling_features_df[ling_features_df.topic_id == bad_topic_id].index)\n",
    "print(ling_features_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in ['dale_chall_score', 'flesch_score', 'ASL']:\n",
    "    attr_list = []\n",
    "\n",
    "    for row in ling_features_df.iterrows():\n",
    "        topic_id = row[1].topic_id\n",
    "        step_id = topic_id_step_id_mapping[topic_id]\n",
    "\n",
    "        corresponding_row = topics_statistics[topics_statistics.step_id == step_id]\n",
    "        assert not corresponding_row.empty, f'In topic statistics there\\'s no row with step_id {step_id}'\n",
    "\n",
    "        attr_value = corresponding_row[attr].values[0]\n",
    "        attr_list.append(attr_value)\n",
    "\n",
    "    ling_features_df[attr] = attr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>hpoint_lemma</th>\n",
       "      <th>Entropy_lemma</th>\n",
       "      <th>verbdistance_lemma</th>\n",
       "      <th>activity</th>\n",
       "      <th>ATL_token</th>\n",
       "      <th>TC_lemma</th>\n",
       "      <th>mattr_lemma_50</th>\n",
       "      <th>dale_chall_score</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>ASL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>905</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.815966</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>3.887262</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.729842</td>\n",
       "      <td>8.658398</td>\n",
       "      <td>63.733344</td>\n",
       "      <td>22.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>906</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>7.080815</td>\n",
       "      <td>7.328571</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>4.051695</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.728612</td>\n",
       "      <td>9.531336</td>\n",
       "      <td>38.968934</td>\n",
       "      <td>29.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>7.413000</td>\n",
       "      <td>8.878788</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>4.363095</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.762795</td>\n",
       "      <td>9.591177</td>\n",
       "      <td>52.834292</td>\n",
       "      <td>16.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>6.981621</td>\n",
       "      <td>6.678899</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>4.055164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754446</td>\n",
       "      <td>8.616742</td>\n",
       "      <td>58.471407</td>\n",
       "      <td>23.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>6.930712</td>\n",
       "      <td>8.065574</td>\n",
       "      <td>0.647368</td>\n",
       "      <td>3.815013</td>\n",
       "      <td>0.043239</td>\n",
       "      <td>0.741551</td>\n",
       "      <td>8.801582</td>\n",
       "      <td>52.769228</td>\n",
       "      <td>31.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  hpoint_lemma  Entropy_lemma  verbdistance_lemma  activity  \\\n",
       "0       905     12.000000       6.815966            6.500000  0.728000   \n",
       "1       906     15.200000       7.080815            7.328571  0.661972   \n",
       "2       909     13.500000       7.413000            8.878788  0.537634   \n",
       "3       910     12.666667       6.981621            6.678899  0.709677   \n",
       "4       911     15.500000       6.930712            8.065574  0.647368   \n",
       "\n",
       "   ATL_token  TC_lemma  mattr_lemma_50  dale_chall_score  flesch_score  \\\n",
       "0   3.887262  0.034531        0.729842          8.658398     63.733344   \n",
       "1   4.051695  0.027688        0.728612          9.531336     38.968934   \n",
       "2   4.363095  0.033896        0.762795          9.591177     52.834292   \n",
       "3   4.055164  0.000000        0.754446          8.616742     58.471407   \n",
       "4   3.815013  0.043239        0.741551          8.801582     52.769228   \n",
       "\n",
       "         ASL  \n",
       "0  22.346154  \n",
       "1  29.843750  \n",
       "2  16.620000  \n",
       "3  23.375000  \n",
       "4  31.600000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ling_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features_df.to_csv('./new_cleaned/train_corpus/all_ling_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add probability of the text from GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try with the first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lm-scorer in /home/anna/.local/lib/python3.6/site-packages (0.4.2)\n",
      "Requirement already satisfied: transformers<3.0.0,>=2.9.0 in /home/anna/.local/lib/python3.6/site-packages (from lm-scorer) (2.11.0)\n",
      "Requirement already satisfied: pip>=20.0.0 in /home/anna/.local/lib/python3.6/site-packages (from lm-scorer) (21.3.1)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.4.0 in /home/anna/.local/lib/python3.6/site-packages (from lm-scorer) (1.9.1+cu111)\n",
      "Requirement already satisfied: dataclasses in /home/anna/.local/lib/python3.6/site-packages (from torch<2.0.0,>=1.4.0->lm-scorer) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/anna/.local/lib/python3.6/site-packages (from torch<2.0.0,>=1.4.0->lm-scorer) (3.7.4.3)\n",
      "Requirement already satisfied: packaging in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (21.0)\n",
      "Requirement already satisfied: requests in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (2020.11.13)\n",
      "Requirement already satisfied: numpy in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (1.19.5)\n",
      "Requirement already satisfied: sentencepiece in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (0.1.95)\n",
      "Requirement already satisfied: filelock in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (3.3.0)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/anna/.local/lib/python3.6/site-packages (from transformers<3.0.0,>=2.9.0->lm-scorer) (0.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/anna/.local/lib/python3.6/site-packages (from packaging->transformers<3.0.0,>=2.9.0->lm-scorer) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anna/.local/lib/python3.6/site-packages (from requests->transformers<3.0.0,>=2.9.0->lm-scorer) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/anna/.local/lib/python3.6/site-packages (from requests->transformers<3.0.0,>=2.9.0->lm-scorer) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/anna/.local/lib/python3.6/site-packages (from requests->transformers<3.0.0,>=2.9.0->lm-scorer) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anna/.local/lib/python3.6/site-packages (from requests->transformers<3.0.0,>=2.9.0->lm-scorer) (3.2)\n",
      "Requirement already satisfied: joblib in /home/anna/.local/lib/python3.6/site-packages (from sacremoses->transformers<3.0.0,>=2.9.0->lm-scorer) (0.17.0)\n",
      "Requirement already satisfied: click in /home/anna/.local/lib/python3.6/site-packages (from sacremoses->transformers<3.0.0,>=2.9.0->lm-scorer) (7.1.2)\n",
      "Requirement already satisfied: six in /home/anna/.local/lib/python3.6/site-packages (from sacremoses->transformers<3.0.0,>=2.9.0->lm-scorer) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install lm-scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lm_scorer.models.auto import AutoLMScorer as LMScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'distilgpt2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(LMScorer.supported_model_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Load model to cpu or cuda\n",
    "available_gpu = torch.cuda.is_available()\n",
    "print(available_gpu)\n",
    "device = \"cuda:0\" if available_gpu else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "     |████████████████████████████████| 123 kB 1.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /home/anna/.local/lib/python3.6/site-packages (from ipywidgets) (5.5.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/anna/.local/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/anna/.local/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/anna/.local/lib/python3.6/site-packages (from ipywidgets) (7.16.1)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.1.1-py3-none-any.whl (245 kB)\n",
      "     |████████████████████████████████| 245 kB 1.8 MB/s            \n",
      "\u001b[?25hCollecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.1-py2.py3-none-any.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 1.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: jupyter-client in /home/anna/.local/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.5)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/anna/.local/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: pickleshare in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: pygments in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: decorator in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/anna/.local/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: six in /home/anna/.local/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/anna/.local/lib/python3.6/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.1.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/anna/.local/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: nbformat in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.7)\n",
      "Requirement already satisfied: nbconvert in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: Send2Trash in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jinja2 in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/anna/.local/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /home/anna/.local/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/anna/.local/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/anna/.local/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: wcwidth in /home/anna/.local/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/anna/.local/lib/python3.6/site-packages (from pexpect->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/anna/.local/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/anna/.local/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: defusedxml in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: bleach in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.5)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/anna/.local/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/anna/.local/lib/python3.6/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pycparser in /home/anna/.local/lib/python3.6/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/anna/.local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/anna/.local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/anna/.local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: async-generator in /home/anna/.local/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: packaging in /home/anna/.local/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: webencodings in /home/anna/.local/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/anna/.local/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/anna/.local/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/anna/.local/lib/python3.6/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-7.7.1 jupyterlab-widgets-1.1.1 widgetsnbextension-3.6.1\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "scorer = LMScorer.from_pretrained(\"gpt2\", device=device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.018320949748158455,\n",
       "  0.006643158383667469,\n",
       "  0.08063255995512009,\n",
       "  0.0006074582342989743,\n",
       "  0.27771326899528503,\n",
       "  0.003638095688074827],\n",
       " [40, 588, 428, 5301, 13, 50256],\n",
       " ['I', 'Ġlike', 'Ġthis', 'Ġpackage', '.', '<|endoftext|>'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return token probabilities\n",
    "scorer.tokens_score(\"I like this package.\")  # the higher, the more probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-3.9997100830078125,\n",
       "  -5.014167785644531,\n",
       "  -2.517852783203125,\n",
       "  -7.406227111816406,\n",
       "  -1.2811660766601562,\n",
       "  -5.616294860839844],\n",
       " [40, 588, 428, 5301, 13, 50256],\n",
       " ['I', 'Ġlike', 'Ġthis', 'Ġpackage', '.', '<|endoftext|>'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.tokens_score(\"I like this package.\", log=True)  # the higher, the more probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't want to use multiplication of tokens' probabilities\n",
    "# cause 1) results will be very small numbers, 2) it will be influences by the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013488700613379478\n",
      "-25.835418701171875\n",
      "[1.1507714052505502e-11, 5.66448667485564e-12]\n",
      "[0.00517506618052721, 0.0036758694332093]\n"
     ]
    }
   ],
   "source": [
    "# Compute sentence score as the geometric mean of tokens' probabilities\n",
    "print(scorer.sentence_score(\"I like this package.\", reduce=\"gmean\"))\n",
    "\n",
    "# Get the log of the sentence score\n",
    "print(scorer.sentence_score(\"I like this package.\", log=True))\n",
    "\n",
    "# Score multiple sentences\n",
    "print(scorer.sentence_score([\"Sentence 1\", \"Sentence 2\"]))\n",
    "print(scorer.sentence_score([\"What a wonderful day\", \"What a wonderful life\"], reduce=\"gmean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.297000885009766, -6.474201202392578]\n"
     ]
    }
   ],
   "source": [
    "print(scorer.sentence_score([\"Sentence 1\", \"Sentence 2\"], reduce='gmean', log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get scores for sentences in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_sm_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = 'Hello, world. Here are two sentences.'\n",
    "doc = en_sm_model(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, world.', 'Here are two sentences.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_sents(text, model):\n",
    "    doc = model(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we score sentences, we need to get sentences for each topic\n",
    "# for now we have cleaned text and lemmatized text\n",
    "# we'll need to go through cleaned texts again, split them into sentences and receive sentence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_statistics = pd.read_csv('./new_cleaned/topics_all_statistics_and_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_id</th>\n",
       "      <th>is_theory</th>\n",
       "      <th>text</th>\n",
       "      <th>seconds_to_complete</th>\n",
       "      <th>last_3_month_completion_rate</th>\n",
       "      <th>last_3_month_completed_step_users_count</th>\n",
       "      <th>last_3_month_avg_like</th>\n",
       "      <th>last_3_month_likes_count</th>\n",
       "      <th>last_3_month_topic_completion_rate</th>\n",
       "      <th>last_3_month_completed_topic_users_count</th>\n",
       "      <th>...</th>\n",
       "      <th>cleaned_texts</th>\n",
       "      <th>num_headings</th>\n",
       "      <th>symbols_in_snippets</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>norm_seconds</th>\n",
       "      <th>ASL</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>dale_chall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12357</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;h5 id=\\\"introduction\\\"&gt; Introduction&lt;/h5&gt;\\n\\...</td>\n",
       "      <td>603.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\" *heading* So far you have learned quite a lo...</td>\n",
       "      <td>6</td>\n",
       "      <td>790</td>\n",
       "      <td>618</td>\n",
       "      <td>24</td>\n",
       "      <td>995</td>\n",
       "      <td>9.764563</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>44.490012</td>\n",
       "      <td>9.180577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12691</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;p&gt;JavaScript was originally developed as a l...</td>\n",
       "      <td>253.21</td>\n",
       "      <td>0.87</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\"JavaScript was originally developed as a lang...</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>605</td>\n",
       "      <td>35</td>\n",
       "      <td>962</td>\n",
       "      <td>4.185289</td>\n",
       "      <td>17.285714</td>\n",
       "      <td>54.769008</td>\n",
       "      <td>9.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8112</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;p&gt;We've already learned what annotations are...</td>\n",
       "      <td>486.94</td>\n",
       "      <td>0.45</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\"We've already learned what annotations are an...</td>\n",
       "      <td>3</td>\n",
       "      <td>1506</td>\n",
       "      <td>610</td>\n",
       "      <td>30</td>\n",
       "      <td>990</td>\n",
       "      <td>7.982623</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>48.895027</td>\n",
       "      <td>9.097296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7892</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;h5&gt;Introduction&lt;/h5&gt;\\n\\n&lt;p&gt;You often hear pe...</td>\n",
       "      <td>542.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\" *heading* You often hear people speak about ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1079</td>\n",
       "      <td>51</td>\n",
       "      <td>1652</td>\n",
       "      <td>5.029935</td>\n",
       "      <td>21.156863</td>\n",
       "      <td>55.834186</td>\n",
       "      <td>9.207762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15809</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;h5&gt;Introduction&lt;/h5&gt;\\n\\n&lt;p&gt;When you have alr...</td>\n",
       "      <td>556.76</td>\n",
       "      <td>0.43</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\" *heading* When you have already learned the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>409</td>\n",
       "      <td>633</td>\n",
       "      <td>21</td>\n",
       "      <td>995</td>\n",
       "      <td>8.795577</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>43.258957</td>\n",
       "      <td>9.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_id  is_theory                                               text  \\\n",
       "0    12357          1  \"<h5 id=\\\"introduction\\\"> Introduction</h5>\\n\\...   \n",
       "1    12691          1  \"<p>JavaScript was originally developed as a l...   \n",
       "2     8112          1  \"<p>We've already learned what annotations are...   \n",
       "3     7892          1  \"<h5>Introduction</h5>\\n\\n<p>You often hear pe...   \n",
       "4    15809          1  \"<h5>Introduction</h5>\\n\\n<p>When you have alr...   \n",
       "\n",
       "   seconds_to_complete  last_3_month_completion_rate  \\\n",
       "0               603.45                          0.56   \n",
       "1               253.21                          0.87   \n",
       "2               486.94                          0.45   \n",
       "3               542.73                          0.72   \n",
       "4               556.76                          0.43   \n",
       "\n",
       "   last_3_month_completed_step_users_count  last_3_month_avg_like  \\\n",
       "0                                     40.0                   2.00   \n",
       "1                                    884.0                   1.72   \n",
       "2                                     50.0                   1.57   \n",
       "3                                     60.0                   2.00   \n",
       "4                                     43.0                   1.40   \n",
       "\n",
       "   last_3_month_likes_count  last_3_month_topic_completion_rate  \\\n",
       "0                      10.0                                0.90   \n",
       "1                      79.0                                0.96   \n",
       "2                       7.0                                0.89   \n",
       "3                       5.0                                0.91   \n",
       "4                      10.0                                0.91   \n",
       "\n",
       "   last_3_month_completed_topic_users_count  ...  \\\n",
       "0                                      35.0  ...   \n",
       "1                                     844.0  ...   \n",
       "2                                      49.0  ...   \n",
       "3                                      58.0  ...   \n",
       "4                                      53.0  ...   \n",
       "\n",
       "                                       cleaned_texts  num_headings  \\\n",
       "0  \" *heading* So far you have learned quite a lo...             6   \n",
       "1  \"JavaScript was originally developed as a lang...             5   \n",
       "2  \"We've already learned what annotations are an...             3   \n",
       "3  \" *heading* You often hear people speak about ...             5   \n",
       "4  \" *heading* When you have already learned the ...             5   \n",
       "\n",
       "  symbols_in_snippets  num_words  num_sentences  num_syllables  norm_seconds  \\\n",
       "0                 790        618             24            995      9.764563   \n",
       "1                  35        605             35            962      4.185289   \n",
       "2                1506        610             30            990      7.982623   \n",
       "3                   0       1079             51           1652      5.029935   \n",
       "4                 409        633             21            995      8.795577   \n",
       "\n",
       "         ASL  flesch_score  dale_chall_score  \n",
       "0  25.750000     44.490012          9.180577  \n",
       "1  17.285714     54.769008          9.896400  \n",
       "2  20.333333     48.895027          9.097296  \n",
       "3  21.156863     55.834186          9.207762  \n",
       "4  30.142857     43.258957          9.721412  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1318, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_special_tokens(text):\n",
    "    for tok in ['*heading*', '*img*', '*code*', '*math*', '*table*']:\n",
    "        text = text.replace(tok, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n"
     ]
    }
   ],
   "source": [
    "# for each topic (step id) we get a list of prbabilities of its sentences\n",
    "step_id_sent_prob_mapping = dict()\n",
    "\n",
    "for i, row in topics_statistics.iterrows():\n",
    "    print(i)\n",
    "    cleaned = row.cleaned_texts\n",
    "    cleaned = delete_special_tokens(cleaned)\n",
    "    \n",
    "    # split into sentences\n",
    "    sentences = get_spacy_sents(cleaned, en_sm_model)\n",
    "    \n",
    "    # compute probability of sentences\n",
    "    sent_probs = scorer.sentence_score(sentences, reduce=\"gmean\")\n",
    "    \n",
    "    step_id_sent_prob_mapping[row.step_id] = sent_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01088960561901331,\n",
       " 0.04942912235856056,\n",
       " 0.013954082503914833,\n",
       " 0.03850657492876053,\n",
       " 0.021659985184669495,\n",
       " 0.04389766976237297,\n",
       " 0.010407773777842522,\n",
       " 0.027493784204125404,\n",
       " 0.02199213206768036,\n",
       " 0.042614661157131195,\n",
       " 0.038606010377407074,\n",
       " 0.04772435873746872,\n",
       " 0.010390409268438816,\n",
       " 0.012639411725103855,\n",
       " 0.013896314427256584,\n",
       " 0.04091031849384308,\n",
       " 0.0265134759247303,\n",
       " 0.06715111434459686,\n",
       " 0.035362791270017624,\n",
       " 0.010581093840301037,\n",
       " 0.02318025752902031,\n",
       " 0.009649845771491528,\n",
       " 0.017345214262604713,\n",
       " 0.008305211551487446,\n",
       " 0.06712324917316437,\n",
       " 0.029575007036328316,\n",
       " 0.033525500446558,\n",
       " 0.024693557992577553,\n",
       " 0.021297771483659744,\n",
       " 0.01655518263578415,\n",
       " 0.017705131322145462,\n",
       " 0.007748128846287727,\n",
       " 0.04461367800831795,\n",
       " 0.043341416865587234,\n",
       " 0.0458516851067543,\n",
       " 0.0178876630961895,\n",
       " 0.02358844503760338]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_id_sent_prob_mapping[12691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(step_id_sent_prob_mapping, open('./new_cleaned/train_corpus/step_id_sent_prob_mapping.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From sentence scores, get a score for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we prepare to write them into a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n"
     ]
    }
   ],
   "source": [
    "df_with_topic_id = pd.read_csv('./new_cleaned/train_corpus/all_ling_features.csv')\n",
    "topic_ids = df_with_topic_id.topic_id.values\n",
    "print(len(topic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id_step_id_map = pickle.load(open('./topic_id_step_id_mapping.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_id_sent_prob_mapping = pickle.load(open('./new_cleaned/train_corpus/step_id_sent_prob_mapping.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_score_from_sentence_scores(topic_id, topic_id_step_id_mapping, step_id_sent_prob_mapping):\n",
    "    corr_step_id = topic_id_step_id_mapping[topic_id]\n",
    "    list_sent_scores = step_id_sent_prob_mapping[corr_step_id]\n",
    "    return statistics.mean(list_sent_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_scores = []\n",
    "for topic_id in topic_ids:\n",
    "    LM_scores.append(get_topic_score_from_sentence_scores(topic_id, topic_id_step_id_mapping, step_id_sent_prob_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_prob_df = pd.DataFrame({'topic_id': topic_ids, 'GPT2_prob': LM_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>GPT2_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>905</td>\n",
       "      <td>0.018858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>906</td>\n",
       "      <td>0.020324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909</td>\n",
       "      <td>0.016106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910</td>\n",
       "      <td>0.022494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911</td>\n",
       "      <td>0.018551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  GPT2_prob\n",
       "0       905   0.018858\n",
       "1       906   0.020324\n",
       "2       909   0.016106\n",
       "3       910   0.022494\n",
       "4       911   0.018551"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_prob_df.to_csv('./new_cleaned/train_corpus/LM_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of overall prereqs - from topic_id_all_prereq_mapping.pkl\n",
    "# the number of direct prereqs - from topic_id_direct_prereq_mapping.pkl\n",
    "# the number of code snippets - the number of *code*\n",
    "\n",
    "# the number of images - need to replace images to *img* in text extraction\n",
    "# the number of sections - need to count headings in text extraction\n",
    "\n",
    "# percent of code in the whole text (in symbols)\n",
    "# the topic group -- from the comments' dump -- DO NOT TAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id_all_prereq_mapping = pickle.load(open('topic_id_all_prereq_mapping.pkl', 'rb'))\n",
    "topic_id_direct_prereq_mapping = pickle.load(open('topic_id_direct_prereq_mapping.pkl', 'rb'))\n",
    "step_id_topic_id_mapping = pickle.load(open('step_id_topic_id_mapping.pkl', 'br'))\n",
    "topic_id_step_id_mapping = pickle.load(open('topic_id_step_id_mapping.pkl', 'br'))\n",
    "\n",
    "topics_statistics = pd.read_csv('./new_cleaned/topics_all_statistics_and_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step_id', 'is_theory', 'text', 'seconds_to_complete',\n",
       "       'last_3_month_completion_rate',\n",
       "       'last_3_month_completed_step_users_count', 'last_3_month_avg_like',\n",
       "       'last_3_month_likes_count', 'last_3_month_topic_completion_rate',\n",
       "       'last_3_month_completed_topic_users_count',\n",
       "       'back_to_theory_times_per_user_session_avg_last_3_month',\n",
       "       'back_to_theory_users_%_last_3_month', 'cleaned_texts', 'num_headings',\n",
       "       'symbols_in_snippets', 'num_words', 'num_sentences', 'num_syllables',\n",
       "       'norm_seconds', 'ASL', 'flesch_score', 'dale_chall_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_statistics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_prereqs(topic_id, topic_id_all_prereq_mapping):\n",
    "    return len(topic_id_all_prereq_mapping[topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direct_prereqs(topic_id, topic_id_direct_prereq_mapping):\n",
    "    return len(topic_id_direct_prereq_mapping[topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_code_snippets(topic_id, topic_statistics_df, topic_id_step_id_mapping):\n",
    "    step_id = topic_id_step_id_mapping[topic_id]\n",
    "    row = topic_statistics_df[topic_statistics_df.step_id == step_id]\n",
    "    text = row.cleaned_texts.values[0]\n",
    "    return text.count(\"*code*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_images(topic_id, topic_statistics_df, topic_id_step_id_mapping):\n",
    "    step_id = topic_id_step_id_mapping[topic_id]\n",
    "    row = topic_statistics_df[topic_statistics_df.step_id == step_id]\n",
    "    text = row.cleaned_texts.values[0]\n",
    "    return text.count(\"*img*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_sections(topic_id, topic_statistics_df, topic_id_step_id_mapping):\n",
    "    step_id = topic_id_step_id_mapping[topic_id]\n",
    "    row = topic_statistics_df[topic_statistics_df.step_id == step_id]\n",
    "    return row.num_headings.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_code(topic_id, topic_statistics_df, topic_id_step_id_mapping):  \n",
    "    # percent of code in symbols, wo spaces\n",
    "    step_id = topic_id_step_id_mapping[topic_id]\n",
    "    row = topic_statistics_df[topic_statistics_df.step_id == step_id]\n",
    "    text = row.cleaned_texts.values[0]\n",
    "    wo_spaces = re.sub(pattern, '', text)\n",
    "    \n",
    "    snippets_len = row.symbols_in_snippets.values[0]\n",
    "    return snippets_len / (len(wo_spaces) + snippets_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_features(topic_id, topic_statistics_df, topic_id_step_id_mapping, \n",
    "                        topic_id_all_prereq_mapping, topic_id_direct_prereq_mapping):\n",
    "    return (get_overall_prereqs(topic_id, topic_id_all_prereq_mapping),\n",
    "            get_direct_prereqs(topic_id, topic_id_direct_prereq_mapping),\n",
    "            get_num_code_snippets(topic_id, topic_statistics_df, topic_id_step_id_mapping),\n",
    "            get_num_images(topic_id, topic_statistics_df, topic_id_step_id_mapping),\n",
    "            get_num_sections(topic_id, topic_statistics_df, topic_id_step_id_mapping),\n",
    "            get_percent_code(topic_id, topic_statistics_df, topic_id_step_id_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a df with meta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n"
     ]
    }
   ],
   "source": [
    "df_with_topic_id = pd.read_csv('./new_cleaned/train_corpus/all_ling_features.csv')\n",
    "topic_ids = df_with_topic_id.topic_id.values\n",
    "print(len(topic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316 1338\n"
     ]
    }
   ],
   "source": [
    "print(len(topic_id_direct_prereq_mapping), len(topic_id_all_prereq_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032\n",
      "1075\n",
      "1114\n",
      "1174\n",
      "350\n",
      "now all prereqs\n"
     ]
    }
   ],
   "source": [
    "# check what topics are not in prereq mappings\n",
    "ids_not_in_mapping = []\n",
    "\n",
    "for t_id in topic_ids:\n",
    "    if t_id not in topic_id_direct_prereq_mapping:\n",
    "        print(t_id)\n",
    "        ids_not_in_mapping.append(t_id)\n",
    "        \n",
    "print('now all prereqs')\n",
    "\n",
    "for t_id in topic_ids:\n",
    "    if t_id not in topic_id_all_prereq_mapping:\n",
    "        print(t_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n",
      "1313\n"
     ]
    }
   ],
   "source": [
    "# for the alg to work without mistakes, let's delete these topic IDs from topic_ids\n",
    "topic_ids = list(topic_ids)\n",
    "print(len(topic_ids))\n",
    "\n",
    "for el in ids_not_in_mapping:\n",
    "    topic_ids.remove(el)\n",
    "    \n",
    "print(len(topic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_features = dict()\n",
    "features_list = ['overall_prereqs', 'direct_prereqs', 'num_snippets', 'num_img', 'num_sections', 'percent_code']\n",
    "\n",
    "for feature in features_list:\n",
    "    dict_features[feature] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_id in topic_ids:\n",
    "        six_values = collect_all_features(topic_id, topics_statistics, topic_id_step_id_mapping,\n",
    "                                          topic_id_all_prereq_mapping, topic_id_direct_prereq_mapping)\n",
    "        \n",
    "        for key, value in zip(dict_features.keys(), six_values):\n",
    "            dict_features[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_features = pd.DataFrame(columns=['topic_id'] + features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_features['topic_id'] = topic_ids\n",
    "for feature in features_list:\n",
    "    df_meta_features[feature] = dict_features[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>overall_prereqs</th>\n",
       "      <th>direct_prereqs</th>\n",
       "      <th>num_snippets</th>\n",
       "      <th>num_img</th>\n",
       "      <th>num_sections</th>\n",
       "      <th>percent_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>905</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.175722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>906</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.401552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>909</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.270630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  overall_prereqs  direct_prereqs  num_snippets  num_img  \\\n",
       "0       905               53               1             5        1   \n",
       "1       906               12               2            15        0   \n",
       "2       909               18               3             4        0   \n",
       "3       910                3               1             0        3   \n",
       "4       911               24               1            15        0   \n",
       "\n",
       "   num_sections  percent_code  \n",
       "0             5      0.175722  \n",
       "1             4      0.401552  \n",
       "2             4      0.013238  \n",
       "3             4      0.000000  \n",
       "4             5      0.270630  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_features.to_csv('./new_cleaned/train_corpus/meta_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll need to disregard average like if it was used to extend the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n"
     ]
    }
   ],
   "source": [
    "df_with_topic_id = pd.read_csv('./new_cleaned/train_corpus/all_ling_features.csv')\n",
    "topic_ids = df_with_topic_id.topic_id.values\n",
    "print(len(topic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_statistics = pd.read_csv('./new_cleaned/topics_all_statistics_and_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318 1318\n"
     ]
    }
   ],
   "source": [
    "print(len(topic_ids), topics_statistics.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_id_topic_id_mapping = pickle.load(open('step_id_topic_id_mapping.pkl', 'br'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step_id', 'is_theory', 'text', 'seconds_to_complete',\n",
       "       'last_3_month_completion_rate',\n",
       "       'last_3_month_completed_step_users_count', 'last_3_month_avg_like',\n",
       "       'last_3_month_likes_count', 'last_3_month_topic_completion_rate',\n",
       "       'last_3_month_completed_topic_users_count',\n",
       "       'back_to_theory_times_per_user_session_avg_last_3_month',\n",
       "       'back_to_theory_users_%_last_3_month', 'cleaned_texts', 'num_headings',\n",
       "       'symbols_in_snippets', 'num_words', 'num_sentences', 'num_syllables',\n",
       "       'norm_seconds', 'ASL', 'flesch_score', 'dale_chall_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_statistics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take only one of the two back_to_theory cause they correlate a lot (0.97)\n",
    "needed_features_w_like = ['norm_seconds', 'last_3_month_completion_rate', 'last_3_month_avg_like',\n",
    "                          'last_3_month_topic_completion_rate', 'back_to_theory_users_%_last_3_month']\n",
    "needed_features_wo_like = ['norm_seconds', 'last_3_month_completion_rate',\n",
    "                          'last_3_month_topic_completion_rate', 'back_to_theory_users_%_last_3_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_statistics_with_completions = topics_statistics[topics_statistics.last_3_month_completed_step_users_count > 20]\n",
    "topics_statistics_with_likes = topics_statistics[topics_statistics.last_3_month_likes_count > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_df(topic_statistics, needed_features, step_id_topic_id_mapping):\n",
    "    dict_w_features = dict()\n",
    "    for feature in ['topic_id'] + needed_features:\n",
    "        dict_w_features[feature] = []\n",
    "    \n",
    "    for i, row in topic_statistics.iterrows():\n",
    "        corr_topic_id = step_id_topic_id_mapping[row.step_id]\n",
    "\n",
    "        dict_w_features['topic_id'].append(corr_topic_id)\n",
    "        for feature in needed_features:\n",
    "            dict_w_features[feature].append(row[feature])  # values[0]\n",
    "\n",
    "    df_result = pd.DataFrame(dict_w_features)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>norm_seconds</th>\n",
       "      <th>last_3_month_completion_rate</th>\n",
       "      <th>last_3_month_avg_like</th>\n",
       "      <th>last_3_month_topic_completion_rate</th>\n",
       "      <th>back_to_theory_users_%_last_3_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313</td>\n",
       "      <td>4.185289</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.96</td>\n",
       "      <td>24.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260</td>\n",
       "      <td>1.955792</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.86</td>\n",
       "      <td>20.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604</td>\n",
       "      <td>4.487571</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>31.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "      <td>3.803515</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>23.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1286</td>\n",
       "      <td>10.688952</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>58.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  norm_seconds  last_3_month_completion_rate  \\\n",
       "0      1313      4.185289                          0.87   \n",
       "1       260      1.955792                          0.88   \n",
       "2       604      4.487571                          0.83   \n",
       "3       215      3.803515                          0.86   \n",
       "4      1286     10.688952                          0.76   \n",
       "\n",
       "   last_3_month_avg_like  last_3_month_topic_completion_rate  \\\n",
       "0                   1.72                                0.96   \n",
       "1                   1.74                                0.86   \n",
       "2                   1.67                                0.90   \n",
       "3                   1.83                                0.82   \n",
       "4                   1.83                                0.74   \n",
       "\n",
       "   back_to_theory_users_%_last_3_month  \n",
       "0                                24.43  \n",
       "1                                20.11  \n",
       "2                                31.50  \n",
       "3                                23.08  \n",
       "4                                58.91  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_likes = fill_in_df(topics_statistics_with_likes, needed_features_w_like, step_id_topic_id_mapping)\n",
    "assert df_with_likes.shape[0] == topics_statistics_with_likes.shape[0]\n",
    "df_with_likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>norm_seconds</th>\n",
       "      <th>last_3_month_completion_rate</th>\n",
       "      <th>last_3_month_topic_completion_rate</th>\n",
       "      <th>back_to_theory_users_%_last_3_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1235</td>\n",
       "      <td>9.764563</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.90</td>\n",
       "      <td>67.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1313</td>\n",
       "      <td>4.185289</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>24.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629</td>\n",
       "      <td>7.982623</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.89</td>\n",
       "      <td>69.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>5.029935</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.91</td>\n",
       "      <td>26.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1685</td>\n",
       "      <td>8.795577</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.91</td>\n",
       "      <td>50.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  norm_seconds  last_3_month_completion_rate  \\\n",
       "0      1235      9.764563                          0.56   \n",
       "1      1313      4.185289                          0.87   \n",
       "2       629      7.982623                          0.45   \n",
       "3       603      5.029935                          0.72   \n",
       "4      1685      8.795577                          0.43   \n",
       "\n",
       "   last_3_month_topic_completion_rate  back_to_theory_users_%_last_3_month  \n",
       "0                                0.90                                67.21  \n",
       "1                                0.96                                24.43  \n",
       "2                                0.89                                69.41  \n",
       "3                                0.91                                26.39  \n",
       "4                                0.91                                50.88  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo_likes = fill_in_df(topics_statistics_with_completions, needed_features_wo_like, step_id_topic_id_mapping)\n",
    "assert df_wo_likes.shape[0] == topics_statistics_with_completions.shape[0]\n",
    "df_wo_likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_likes.to_csv('./new_cleaned/train_corpus/statistics_with_likes.csv', index=False)\n",
    "df_wo_likes.to_csv('./new_cleaned/train_corpus/statistics_without_likes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
